{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:19.261961Z",
     "start_time": "2021-01-07T10:12:19.248017Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义两个list分别存放两个板块的帖子数据\n",
    "academy_titles = []\n",
    "job_titles = []\n",
    "with open('../Chapter 05/academy_titles.txt', encoding='utf8') as f:\n",
    "    for l in f:  # 按行读取文件\n",
    "        academy_titles.append(l.strip())  # strip 方法用于去掉行尾空格\n",
    "with open('../Chapter 05/job_titles.txt', encoding='utf8') as f:\n",
    "    for l in f:  # 按行读取文件\n",
    "        job_titles.append(l.strip())  # strip 方法用于去掉行尾空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:19.977971Z",
     "start_time": "2021-01-07T10:12:19.969237Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for title in academy_titles:\n",
    "    data_list.append([title, 0])\n",
    "\n",
    "for title in job_titles:\n",
    "    data_list.append([title, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:20.844124Z",
     "start_time": "2021-01-07T10:12:20.834090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for case in data_list:\n",
    "    max_length = max(max_length, len(case[0])+2)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:23.068424Z",
     "start_time": "2021-01-07T10:12:21.502219Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_list, dev_list = train_test_split(data_list,test_size=0.3,random_state=15,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:26.646252Z",
     "start_time": "2021-01-07T10:12:23.069489Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "max_train_epochs = 6\n",
    "warmup_proportion = 0.05\n",
    "gradient_accumulation_steps = 2\n",
    "train_batch_size = 16\n",
    "valid_batch_size = train_batch_size\n",
    "test_batch_size = train_batch_size\n",
    "data_workers= 2\n",
    "\n",
    "learning_rate=1e-6\n",
    "weight_decay=0.01\n",
    "max_grad_norm=1.0\n",
    "cur_time = time.strftime(\"%Y-%m-%d_%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:27.565338Z",
     "start_time": "2021-01-07T10:12:26.647584Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        title = example[0]\n",
    "        label = example[1]\n",
    "        r = tokenizer.encode_plus(title, max_length=max_length, padding=\"max_length\")\n",
    "        return title, label, index#, r['token_type_ids'], label, index\n",
    "\n",
    "def the_collate_fn(batch):\n",
    "    r = tokenizer([b[0] for b in batch], padding=True)\n",
    "    input_ids = torch.LongTensor(r['input_ids'])\n",
    "    attention_mask = torch.LongTensor(r['attention_mask'])\n",
    "    label = torch.LongTensor([b[1] for b in batch])\n",
    "    indexs = [b[2] for b in batch]\n",
    "    return input_ids, attention_mask, label, indexs #, token_type_ids\n",
    "\n",
    "train_dataset = MyDataSet(train_list)\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers=data_workers,\n",
    "    collate_fn=the_collate_fn,\n",
    ")\n",
    "\n",
    "dev_dataset = MyDataSet(dev_list)\n",
    "dev_data_loader = torch.utils.data.DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers=data_workers,\n",
    "    collate_fn=the_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:27.578031Z",
     "start_time": "2021-01-07T10:12:27.567923Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_score():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for step, batch in enumerate(tqdm(dev_data_loader)):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            input_ids, attention_mask = (b.to(device) for b in batch[:2])\n",
    "        y_true += batch[2].numpy().tolist()\n",
    "        logist = model(input_ids, attention_mask)[0]\n",
    "        result = torch.argmax(logist, 1).cpu().numpy().tolist()\n",
    "        y_pred += result\n",
    "    correct = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:22:02.422597Z",
     "start_time": "2021-01-07T10:22:02.419782Z"
    }
   },
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:43.180553Z",
     "start_time": "2021-01-07T10:12:27.580304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup steps : 46\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese')\n",
    "model.to(device)\n",
    "\n",
    "t_total = len(train_data_loader) // gradient_accumulation_steps * max_train_epochs + 1\n",
    "num_warmup_steps = int(warmup_proportion * t_total)\n",
    "print('warmup steps : %d' % num_warmup_steps)\n",
    "no_decay = ['bias', 'LayerNorm.weight'] # no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "param_optimizer = list(model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay': weight_decay},\n",
    "    {'params':[p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:12:46.641068Z",
     "start_time": "2021-01-07T10:12:46.634289Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_test(title):\n",
    "    r = tokenizer([title])\n",
    "    input_ids = torch.LongTensor(r['input_ids']).to(device)\n",
    "    attention_mask = torch.LongTensor(r['attention_mask']).to(device)\n",
    "    logist = model(input_ids, attention_mask)[0]\n",
    "    result = torch.argmax(logist, 1).cpu().numpy().tolist()[0]\n",
    "    result = ['考研考博', '招聘信息'][result]\n",
    "    print(title, result)\n",
    "def print_cases():\n",
    "    print_test('考研心得')\n",
    "    print_test('北大实验室博士')\n",
    "    print_test('考外校博士')\n",
    "    print_test('北大实验室招博士')\n",
    "    print_test('工作or考研?')\n",
    "    print_test('急求自然语言处理工程师')\n",
    "    print_test('校招offer比较')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T10:17:26.475056Z",
     "start_time": "2021-01-07T10:12:48.170852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:41<00:00,  7.52it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 Epoch Mean Loss 0.0391 Time 0.69 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:04<00:00, 26.92it/s]\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9901547116736991\n",
      "考研心得 考研考博\n",
      "北大实验室博士 考研考博\n",
      "考外校博士 考研考博\n",
      "北大实验室招博士 招聘信息\n",
      "工作or考研? 考研考博\n",
      "急求自然语言处理工程师 招聘信息\n",
      "校招offer比较 招聘信息\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:41<00:00,  7.55it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2 Epoch Mean Loss 0.0194 Time 0.69 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:05<00:00, 26.79it/s]\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9971870604781997\n",
      "考研心得 考研考博\n",
      "北大实验室博士 考研考博\n",
      "考外校博士 考研考博\n",
      "北大实验室招博士 招聘信息\n",
      "工作or考研? 考研考博\n",
      "急求自然语言处理工程师 招聘信息\n",
      "校招offer比较 招聘信息\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:41<00:00,  7.55it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 3 Epoch Mean Loss 0.0400 Time 0.69 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:05<00:00, 26.79it/s]\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981247069854665\n",
      "考研心得 考研考博\n",
      "北大实验室博士 考研考博\n",
      "考外校博士 考研考博\n",
      "北大实验室招博士 招聘信息\n",
      "工作or考研? 考研考博\n",
      "急求自然语言处理工程师 招聘信息\n",
      "校招offer比较 招聘信息\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:41<00:00,  7.52it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 4 Epoch Mean Loss 0.0089 Time 0.69 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:05<00:00, 26.74it/s]\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985935302390999\n",
      "考研心得 考研考博\n",
      "北大实验室博士 考研考博\n",
      "考外校博士 考研考博\n",
      "北大实验室招博士 招聘信息\n",
      "工作or考研? 招聘信息\n",
      "急求自然语言处理工程师 招聘信息\n",
      "校招offer比较 招聘信息\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:41<00:00,  7.55it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 5 Epoch Mean Loss 0.0051 Time 0.69 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:05<00:00, 26.79it/s]\n",
      "  0%|          | 0/311 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985935302390999\n",
      "考研心得 考研考博\n",
      "北大实验室博士 考研考博\n",
      "考外校博士 考研考博\n",
      "北大实验室招博士 招聘信息\n",
      "工作or考研? 招聘信息\n",
      "急求自然语言处理工程师 招聘信息\n",
      "校招offer比较 招聘信息\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [00:41<00:00,  7.54it/s]\n",
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 6 Epoch Mean Loss 0.0085 Time 0.69 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [00:05<00:00, 26.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985935302390999\n",
      "考研心得 考研考博\n",
      "北大实验室博士 考研考博\n",
      "考外校博士 考研考博\n",
      "北大实验室招博士 招聘信息\n",
      "工作or考研? 招聘信息\n",
      "急求自然语言处理工程师 招聘信息\n",
      "校招offer比较 招聘信息\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_train_epochs):\n",
    "    b_time = time.time()\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_data_loader)):\n",
    "        input_ids, attention_mask, label = (b.to(device) for b in batch[:-1])\n",
    "        loss = model(input_ids, attention_mask, labels=label)\n",
    "        loss = loss[0]\n",
    "        loss.backward()\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad()\n",
    "    print('Epoch = %d Epoch Mean Loss %.4f Time %.2f min' % (epoch+1, loss.item(), (time.time() - b_time)/60))\n",
    "    print(get_score())\n",
    "    print_cases()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
