{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T22:47:31.144774Z",
     "start_time": "2021-01-06T22:47:31.141501Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T22:47:31.568412Z",
     "start_time": "2021-01-06T22:47:31.520891Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextSpliter(object):\n",
    "    def __init__(self, corpus_path, encoding='utf8', debug=False, verbose=False, max_load_word_length=4):\n",
    "        self.debug = debug\n",
    "        self.verbose = verbose\n",
    "        self.dict = {}\n",
    "        self.dict2 = {}\n",
    "        self.max_word_length = 1\n",
    "        begin_time = time.time()\n",
    "        self.__log__('start load corpus from %s' % corpus_path, 'msg')\n",
    "        # 加载语料\n",
    "        with open(corpus_path, 'r', encoding=encoding) as f:\n",
    "            for l in f:\n",
    "                wds = l.strip().split('  ')\n",
    "                l.replace('[', '')\n",
    "                l.replace(']', '')\n",
    "                last_wd = ''\n",
    "                for i in range(1, len(wds)): # 下标从1开始，因为每行第一个词是标签\n",
    "                    try:\n",
    "                        wd, type = wds[i].split('/')\n",
    "                    except:\n",
    "                        self.__log__('word load error, %s' % wds[i], 'debug')\n",
    "                        continue\n",
    "                    if len(wd) == 0 or len(wd) > max_load_word_length or not wd.isalpha():\n",
    "                        continue\n",
    "                    if wd not in self.dict:\n",
    "                        self.dict[wd] = 0\n",
    "                        if len(wd) > self.max_word_length:\n",
    "                            # 更新最大词长度\n",
    "                            self.max_word_length = len(wd)\n",
    "                            self.__log__('max_word_length=%d, word is %s' %(self.max_word_length, wd), 'debug')\n",
    "                    self.dict[wd] += 1\n",
    "                    if last_wd:\n",
    "                        if last_wd+':'+wd not in self.dict2:\n",
    "                            self.dict2[last_wd+':'+wd] = 0\n",
    "                        self.dict2[last_wd+':'+wd] += 1\n",
    "                    last_wd = wd\n",
    "                    \n",
    "        self.words_cnt = 0\n",
    "        self.words2_cnt = 0\n",
    "        max_c = 0\n",
    "        for wd in self.dict:\n",
    "            self.words_cnt += self.dict[wd]\n",
    "            if self.dict[wd] > max_c:\n",
    "                max_c = self.dict[wd]\n",
    "                wdxx = wd\n",
    "        for wd in self.dict2:\n",
    "            self.words2_cnt += self.dict2[wd]\n",
    "        self.__log__('load corpus finished, %d words in dict and frequency is %d, %d words in dict2 frequency is %d' % (len(self.dict),len(self.dict2), self.words_cnt, self.words2_cnt), 'msg')\n",
    "        self.__log__('%f seconds elapsed' % (time.time()-begin_time), 'msg')\n",
    "    \n",
    "    def split(self, text):\n",
    "        sentence = ''\n",
    "        result = ''\n",
    "        for ch in text:\n",
    "            if not ch.isalpha():\n",
    "                result += self.__split_sentence__(sentence) + ' ' + ch + ' '\n",
    "                sentence = ''\n",
    "            else:\n",
    "                sentence += ch\n",
    "        return result.strip(' ')\n",
    "    \n",
    "    def __get_a_split__(self, cur_split, i):\n",
    "        if i >= len(self.cur_sentence):\n",
    "            self.split_set.append(cur_split)\n",
    "            return\n",
    "        j = min(self.max_word_length, len(self.cur_sentence) - i + 1)\n",
    "        while j > 0:\n",
    "            if j == 1 or self.cur_sentence[i:i+j] in self.dict:\n",
    "                self.__get_a_split__(cur_split + [self.cur_sentence[i:i+j]], i+j)\n",
    "                if j == 2:\n",
    "                    break\n",
    "            j -= 1\n",
    "    \n",
    "    def __get_cnt__(self, dictx, key):\n",
    "        try:\n",
    "            return dictx[key] + 1\n",
    "        except KeyError:\n",
    "            return 1\n",
    "    \n",
    "    def __get_word_probablity__(self, wd, pioneer=''):\n",
    "        if pioneer == '':\n",
    "            return self.__get_cnt__(self.dict, wd) / self.words_cnt\n",
    "        return self.__get_cnt__(self.dict2, pioneer + ':' + wd) / self.__get_cnt__(self.dict, pioneer)\n",
    "    \n",
    "    def __calc_probability__(self, sequence):\n",
    "        probability = 1\n",
    "        pioneer = ''\n",
    "        for wd in sequence:\n",
    "            probability *= self.__get_word_probablity__(wd, pioneer)\n",
    "            pioneer = wd\n",
    "        return probability\n",
    "    \n",
    "    def __split_sentence__(self, sentence):\n",
    "        if len(sentence) == 0:\n",
    "            return ''\n",
    "        self.cur_sentence = sentence.strip()\n",
    "        self.split_set = []\n",
    "        self.__get_a_split__([], 0)\n",
    "        self.__log__(sentence + str(len(self.split_set)),  'debug')\n",
    "        max_probability = 0\n",
    "        for splitx in self.split_set:\n",
    "            probability = self.__calc_probability__(splitx)\n",
    "            self.__log__(str(splitx)+ ' - ' +str(probability), 'debug')\n",
    "            if probability > max_probability:\n",
    "                max_probability = probability\n",
    "                best_split = splitx\n",
    "        return ' '.join(best_split)\n",
    "    \n",
    "    def __log__(self, msg, level='info'):\n",
    "        if level == 'info' and self.verbose:\n",
    "            print (msg)\n",
    "        elif level == 'debug' and self.debug:\n",
    "            print (msg)\n",
    "        elif level == 'error':\n",
    "            print (msg, file=sys.stderr)\n",
    "        elif level == 'msg':\n",
    "            print (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-06T22:47:33.535063Z",
     "start_time": "2021-01-06T22:47:32.069014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start load corpus from ./199801.txt\n",
      "load corpus finished, 49689 words in dict and frequency is 463624, 912534 words in dict2 frequency is 893149\n",
      "1.461231 seconds elapsed\n",
      "time elapsed 1.461527\n"
     ]
    }
   ],
   "source": [
    "btime = time.time()\n",
    "base_path = '.'# os.path.dirname(os.path.realpath(__file__))\n",
    "spliter = TextSpliter(os.path.join(base_path, '199801.txt'), debug=False, verbose=True)\n",
    "print ('time elapsed %f' % (time.time() - btime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
