{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:58:17.742592Z",
     "start_time": "2021-01-07T11:58:14.018119Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "with open('w2id++.json', 'r') as f:\n",
    "    w2id = json.load(f)\n",
    "with open('id2w++.json', 'r') as f:\n",
    "    id2w = json.load(f)\n",
    "    \n",
    "data_list = []\n",
    "with open('data_splited++.jl', 'r') as f:\n",
    "    for l in f:\n",
    "        data_list.append(json.loads(l))\n",
    "embedding = []\n",
    "with open('embedding++.jl', 'r') as f:\n",
    "    for l in f:\n",
    "        embedding.append(json.loads(l))\n",
    "        \n",
    "batch_size = 128\n",
    "data_workers = 4\n",
    "learning_rate = 0.0001\n",
    "gradient_accumulation_steps = 1\n",
    "max_train_epochs = 30\n",
    "warmup_proportion = 0.05\n",
    "weight_decay=0.01\n",
    "max_grad_norm=1.0\n",
    "cur_time = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:58:17.940981Z",
     "start_time": "2021-01-07T11:58:17.743925Z"
    }
   },
   "outputs": [],
   "source": [
    "dlx = [[] for _ in range(5)]\n",
    "for d in data_list:\n",
    "    dlx[len(d[0]) - 5].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:58:22.546919Z",
     "start_time": "2021-01-07T11:58:22.519271Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        s1 = example[0]\n",
    "        s2 = example[1]\n",
    "        return s1, s2, index\n",
    "def str2id(s):\n",
    "    ids = []\n",
    "    for ch in s:\n",
    "        if ch in w2id:\n",
    "            ids.append(w2id[ch])\n",
    "        else:\n",
    "            ids.append(0)\n",
    "    return ids\n",
    "def the_collate_fn(batch):\n",
    "    s1x = []\n",
    "    s2x = []\n",
    "    for b in batch:\n",
    "        s1 = str2id(b[0])\n",
    "        s2 = str2id(b[1])\n",
    "        s1x.append(s1)\n",
    "        s2x.append(s2)\n",
    "    indexs = [b[2] for b in batch]\n",
    "    s1 = torch.LongTensor(s1x)\n",
    "    s2 = torch.LongTensor(s2x)\n",
    "    return s1, s2, indexs\n",
    "\n",
    "dldx = []\n",
    "for d in dlx:\n",
    "    ds = MyDataSet(d)\n",
    "    dld = torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers=data_workers,\n",
    "        collate_fn=the_collate_fn,\n",
    "    )\n",
    "    dldx.append(dld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:59:49.997308Z",
     "start_time": "2021-01-07T11:59:49.927820Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, s1, s2=None):\n",
    "        batch_size, length = s1.shape[:2]\n",
    "        s1 = self.encoder(s1) * math.sqrt(self.ninp)\n",
    "        s1 = self.pos_encoder(s1)\n",
    "        output = self.transformer_encoder(s1)\n",
    "        output = self.decoder(output)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        if s2 is not None:\n",
    "            criterion = nn.NLLLoss()\n",
    "            loss = criterion(output.view(batch_size*length, -1), s2.view(batch_size*length))\n",
    "            return loss\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:59:55.161487Z",
     "start_time": "2021-01-07T11:59:52.899583Z"
    }
   },
   "outputs": [],
   "source": [
    "ntokens = len(w2id)\n",
    "emsize = 300 # embedding dimension\n",
    "nhid = 256 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:59:55.167316Z",
     "start_time": "2021-01-07T11:59:55.162811Z"
    }
   },
   "outputs": [],
   "source": [
    "def t2s(t):\n",
    "    l = t.cpu().tolist()\n",
    "    r = [id2w[x] for x in l[0]]\n",
    "    return ''.join(r)\n",
    "\n",
    "def get_next(s):\n",
    "    ids = torch.LongTensor(str2id(s))\n",
    "    print(s)\n",
    "    ids = ids.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        r = model(ids)\n",
    "        r = r.argmax(dim=2)\n",
    "        return t2s(r)\n",
    "def print_cases():\n",
    "    print(get_next('好好学习') + '\\n')\n",
    "    print(get_next('白日依山尽') + '\\n')\n",
    "    print(get_next('学而时习之') + '\\n')\n",
    "    print(get_next('人之初性本善') + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:59:56.347666Z",
     "start_time": "2021-01-07T11:59:56.169994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "薇亦畚呜\n",
      "\n",
      "白日依山尽\n",
      "呜缁搏鼐识\n",
      "\n",
      "学而时习之\n",
      "飓遵壕鼐摆\n",
      "\n",
      "人之初性本善\n",
      "葫俞檠杜灼蹇\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T11:59:58.738571Z",
     "start_time": "2021-01-07T11:59:58.013432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup steps : 1675108\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "t_total = len(data_list) // gradient_accumulation_steps * max_train_epochs + 1\n",
    "num_warmup_steps = int(warmup_proportion * t_total)\n",
    "\n",
    "print('warmup steps : %d' % num_warmup_steps)\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight'] # no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "param_optimizer = list(model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay': weight_decay},\n",
    "    {'params':[p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T14:14:12.444339Z",
     "start_time": "2021-01-07T12:00:00.625712Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8729/8729 [07:45<00:00, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "流摇深虬\n",
      "\n",
      "白日依山尽\n",
      "临春不不不\n",
      "\n",
      "学而时习之\n",
      "□归枵弹自\n",
      "\n",
      "人之初性本善\n",
      "不自不春一峦\n",
      "\n",
      "8.870945400248967\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8729/8729 [07:47<00:00, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "深一□不\n",
      "\n",
      "白日依山尽\n",
      "无不一不不\n",
      "\n",
      "学而时习之\n",
      "无不此不一\n",
      "\n",
      "人之初性本善\n",
      "不为不一一一\n",
      "\n",
      "7.897064124711264\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [07:43<00:00, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "不不不风\n",
      "\n",
      "白日依山尽\n",
      "不山不不不\n",
      "\n",
      "学而时习之\n",
      "何风不不风\n",
      "\n",
      "人之初性本善\n",
      "不不不不不山\n",
      "\n",
      "7.370467955854356\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [07:56<00:00, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "一此日自\n",
      "\n",
      "白日依山尽\n",
      "年时有无人\n",
      "\n",
      "学而时习之\n",
      "人知自风山\n",
      "\n",
      "人之初性本善\n",
      "人来人云人人\n",
      "\n",
      "7.27033402483921\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [07:26<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "人何人风\n",
      "\n",
      "白日依山尽\n",
      "人风不为生\n",
      "\n",
      "学而时习之\n",
      "人云生风人\n",
      "\n",
      "人之初性本善\n",
      "人年人风生风\n",
      "\n",
      "7.240776638861713\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [08:09<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "未无不风\n",
      "\n",
      "白日依山尽\n",
      "年生人不名\n",
      "\n",
      "学而时习之\n",
      "天有生风人\n",
      "\n",
      "人之初性本善\n",
      "人我风风人何\n",
      "\n",
      "7.21359644739539\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8729/8729 [07:53<00:00, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "流声日风\n",
      "\n",
      "白日依山尽\n",
      "春风不风人\n",
      "\n",
      "学而时习之\n",
      "清有我风山\n",
      "\n",
      "人之初性本善\n",
      "不游一不风风\n",
      "\n",
      "7.182166251535061\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [07:59<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "归天日风\n",
      "\n",
      "白日依山尽\n",
      "春风无为归\n",
      "\n",
      "学而时习之\n",
      "心不不风楼\n",
      "\n",
      "人之初性本善\n",
      "不回不不不事\n",
      "\n",
      "7.145359160251125\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8729/8729 [07:54<00:00, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "归新来风\n",
      "\n",
      "白日依山尽\n",
      "春风一水归\n",
      "\n",
      "学而时习之\n",
      "春有上风山\n",
      "\n",
      "人之初性本善\n",
      "得山一春人作\n",
      "\n",
      "7.098595275332388\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [07:53<00:00, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "春春中春\n",
      "\n",
      "白日依山尽\n",
      "秋时不水新\n",
      "\n",
      "学而时习之\n",
      "年不有风月\n",
      "\n",
      "人之初性本善\n",
      "日涯不无未山\n",
      "\n",
      "7.050091004194025\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [07:54<00:00, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "新新日千\n",
      "\n",
      "白日依山尽\n",
      "青云一水生\n",
      "\n",
      "学而时习之\n",
      "中两有何见\n",
      "\n",
      "人之初性本善\n",
      "上之不明未流\n",
      "\n",
      "7.00925423477304\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 6116/8729 [05:27<02:22, 18.38it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 8729/8729 [07:56<00:00, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "归长见风\n",
      "\n",
      "白日依山尽\n",
      "青年一上还\n",
      "\n",
      "学而时习之\n",
      "上有处不之\n",
      "\n",
      "人之初性本善\n",
      "有之不不无与\n",
      "\n",
      "6.887981681550471\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8729/8729 [08:01<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好好学习\n",
      "何何觉长\n",
      "\n",
      "白日依山尽\n",
      "青天不水长\n",
      "\n",
      "学而时习之\n",
      "日不日不之\n",
      "\n",
      "人之初性本善\n",
      "见之不在亦与\n",
      "\n",
      "6.845888587875147\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 410/8729 [00:20<06:54, 20.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b405de46abdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "for e in range(max_train_epochs):\n",
    "    print(e)\n",
    "    loss_sum = 0\n",
    "    c = 0\n",
    "    xxx = [x.__iter__() for x in dldx]\n",
    "    j = 0\n",
    "    for i in tqdm(range((len(data_list)//batch_size) + 5)):\n",
    "        if len(xxx) == 0:\n",
    "            break\n",
    "        j = j % len(xxx)\n",
    "        try:\n",
    "            batch = xxx[j].__next__()\n",
    "        except StopIteration:\n",
    "            xxx.pop(j)\n",
    "            continue\n",
    "        j += 1\n",
    "        s1, s2, index = batch\n",
    "        s1 = s1.to(device)\n",
    "        s2 = s2.to(device)\n",
    "        loss = model(s1, s2)\n",
    "        loss_sum += loss.item()\n",
    "        c += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "        optimizer.zero_grad()\n",
    "    print_cases()\n",
    "    print(loss_sum / c)\n",
    "    loss_list.append(loss_sum / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T17:07:39.434756Z",
     "start_time": "2020-12-27T17:07:32.630988Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fadeb1cb2b0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot([i for i in range(len(loss_list))], loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T17:20:06.036445Z",
     "start_time": "2020-12-27T17:20:05.965579Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'transform_model_parameter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T17:20:24.760394Z",
     "start_time": "2020-12-27T17:20:24.541552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type TransformerModel. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
      "/usr/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type PositionalEncoding. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'transform_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.load('rnn_model.pkl'))\n",
    "rnn.load_state_dict(torch.load('rnn_parameter.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
