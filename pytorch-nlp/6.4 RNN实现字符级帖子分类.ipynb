{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.583066Z",
     "end_time": "2023-05-03T14:47:24.742645Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义两个list分别存放两个板块的帖子数据\n",
    "import jieba\n",
    "academy_titles = []\n",
    "job_titles = []\n",
    "with open('academy_titles.txt', encoding='utf8') as f:\n",
    "    for l in f:  # 按行读取文件\n",
    "        academy_titles.append(list(jieba.cut(l.strip( ))))  # strip 方法用于去掉行尾空格\n",
    "with open('job_titles.txt', encoding='utf8') as f:\n",
    "    for l in f:  # 按行读取文件\n",
    "        job_titles.append(list(jieba.cut(l.strip( ))))  # strip 方法用于去掉行尾空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "academy_titles[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.743534Z",
     "end_time": "2023-05-03T14:47:24.745977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "for title in academy_titles:\n",
    "    for word in title:\n",
    "        word_set.add(word)\n",
    "for title in job_titles:\n",
    "    for word in title:\n",
    "        word_set.add(word)\n",
    "print(len(word_set))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.752262Z",
     "end_time": "2023-05-03T14:47:24.754637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.755710Z",
     "end_time": "2023-05-03T14:47:24.757336Z"
    }
   },
   "outputs": [],
   "source": [
    "# char_set = set()\n",
    "# for title in academy_titles:\n",
    "#     for ch in title:\n",
    "#         char_set.add(ch)\n",
    "# for title in job_titles:\n",
    "#     for ch in title:\n",
    "#         char_set.add(ch)\n",
    "# print(len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.757912Z",
     "end_time": "2023-05-03T14:47:24.759559Z"
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('word_list', 'w') as f:\n",
    "#     json.dump(word_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.763788Z",
     "end_time": "2023-05-03T14:47:24.779664Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "word_list = list(word_set)\n",
    "n_chars = len(word_set) + 1 # 加一个 UNK\n",
    "\n",
    "def title_to_tensor(title):\n",
    "    tensor = torch.zeros(len(title), dtype=torch.long)\n",
    "    for li,word in enumerate(title):\n",
    "        try:\n",
    "            ind = word_list.index(word)\n",
    "        except ValueError:\n",
    "            ind = n_chars - 1\n",
    "        tensor[li] = ind\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.764858Z",
     "end_time": "2023-05-03T14:47:24.780022Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, word_count, embedding_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = torch.nn.Embedding(word_count, embedding_size)\n",
    "        self.i2h = nn.Linear(embedding_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(embedding_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_tensor, hidden):\n",
    "        word_vector = self.embedding(input_tensor)\n",
    "        combined = torch.cat((word_vector, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "def run_rnn(rnn, input_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    for i in range(input_tensor.size()[0]):\n",
    "        output, hidden = rnn.forward(input_tensor[i].unsqueeze(dim=0), hidden)\n",
    "    return output\n",
    "\n",
    "def train(rnn, criterion, input_tensor, category_tensor):\n",
    "    rnn.zero_grad()\n",
    "    output = run_rnn(rnn, input_tensor)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # 根据梯度更新模型的参数\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# embedding_size = 100\n",
    "# n_hidden = 128\n",
    "# n_categories = 2\n",
    "# rnn = RNN(n_chars, embedding_size, n_hidden, n_categories)\n",
    "#\n",
    "# input_tensor = title_to_tensor(academy_titles[0])\n",
    "# print('input_tensor:\\n', input_tensor)\n",
    "#\n",
    "# hidden = rnn.initHidden()\n",
    "# output, hidden = rnn.forward(input_tensor[0].unsqueeze(dim=0), hidden)\n",
    "# print('output:\\n', output)\n",
    "# print('hidden:\\n', hidden)\n",
    "# print('size of hidden:\\n', hidden.size())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:24.779869Z",
     "end_time": "2023-05-03T14:47:26.283679Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:26.286601Z",
     "end_time": "2023-05-03T14:47:26.295534Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_data = []\n",
    "categories = [\"考研考博\", \"招聘信息\"]\n",
    "\n",
    "for l in academy_titles:\n",
    "    all_data.append((title_to_tensor(l), torch.tensor([0], dtype=torch.long)))\n",
    "for l in job_titles:\n",
    "    all_data.append((title_to_tensor(l), torch.tensor([1], dtype=torch.long)))\n",
    "\n",
    "random.shuffle(all_data)\n",
    "data_len = len(all_data)\n",
    "split_ratio = 0.7\n",
    "train_data = all_data[:int(data_len*split_ratio)]\n",
    "test_data = all_data[int(data_len*split_ratio):]\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:26.299485Z",
     "end_time": "2023-05-03T14:47:26.301274Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(rnn, input_tensor):\n",
    "    with torch.no_grad():\n",
    "        rnn.initHidden()\n",
    "        output = run_rnn(rnn, input_tensor)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T14:47:26.301688Z",
     "end_time": "2023-05-03T14:47:26.303403Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T10:47:31.521470Z",
     "start_time": "2020-09-08T10:45:41.370202Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "epoch = 1\n",
    "embedding_size = 200\n",
    "n_hidden = 10\n",
    "n_categories = 2\n",
    "learning_rate = 0.005\n",
    "rnn = RNN(n_chars, embedding_size, n_hidden, n_categories)\n",
    "# rnn.train()\n",
    "criterion = nn.NLLLoss()\n",
    "loss_sum = 0\n",
    "all_losses = []\n",
    "plot_every = 100\n",
    "for e in range(epoch):\n",
    "    for ind, (title_tensor, label) in enumerate(tqdm(train_data)):\n",
    "        output, loss = train(rnn, criterion, title_tensor, label)\n",
    "        loss_sum += loss\n",
    "        if ind % plot_every == 0:\n",
    "            all_losses.append(loss_sum / plot_every)\n",
    "            loss_sum = 0\n",
    "    c = 0\n",
    "    for title, category in tqdm(test_data):\n",
    "        output = evaluate(rnn, title)\n",
    "        topn, topi = output.topk(1)\n",
    "        if topi.item() == category[0].item():\n",
    "            c += 1\n",
    "    print('accuracy', c / len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:34:02.972596Z",
     "start_time": "2020-08-20T13:33:58.836172Z"
    }
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "l1 = []\n",
    "l2 = []\n",
    "for title, category in tqdm(test_data):\n",
    "    output = evaluate(rnn, title)\n",
    "    topn, topi = output.topk(1)\n",
    "    l1.append(topi.item())\n",
    "    l2.append(category[0].item())\n",
    "    if topi.item() == category[0].item():\n",
    "        c += 1\n",
    "print('accuracy', c / len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:34:12.363857Z",
     "start_time": "2020-08-20T13:34:12.348897Z"
    }
   },
   "outputs": [],
   "source": [
    "print(l1[:40])\n",
    "print(l2[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:34:24.323156Z",
     "start_time": "2020-08-20T13:34:24.315177Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:34:27.957712Z",
     "start_time": "2020-08-20T13:34:27.946694Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:28:46.089108Z",
     "start_time": "2020-08-20T13:28:42.250574Z"
    }
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for title, category in tqdm(test_data):\n",
    "    output = evaluate(rnn, title)\n",
    "    topn, topi = output.topk(1)\n",
    "    if topi.item() == category[0].item():\n",
    "        c += 1\n",
    "print('accuracy', c / len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T11:33:29.900689Z",
     "start_time": "2020-09-08T11:33:29.728794Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(all_losses[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:01:52.495244Z",
     "start_time": "2020-08-20T13:01:52.303270Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.ylabel('Average Loss')\n",
    "plt.plot(all_losses[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:16:40.170444Z",
     "start_time": "2020-08-20T13:16:40.064366Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(rnn, 'rnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:24:52.707246Z",
     "start_time": "2020-08-20T13:24:52.698271Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_category(rnn, title):\n",
    "    input_tensor = title_to_tensor(title)\n",
    "    with torch.no_grad():\n",
    "        rnn.initHidden()\n",
    "        output = run_rnn(rnn, input_tensor)\n",
    "        topv, topi = output.topk(1)\n",
    "        return categories[topi.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:30:17.778502Z",
     "start_time": "2020-08-20T13:30:17.773516Z"
    }
   },
   "outputs": [],
   "source": [
    "input_tensor = title_to_tensor(\"北大实验室招硕博连读保研学生\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:30:20.644213Z",
     "start_time": "2020-08-20T13:30:20.626262Z"
    }
   },
   "outputs": [],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:30:33.621716Z",
     "start_time": "2020-08-20T13:30:33.610744Z"
    }
   },
   "outputs": [],
   "source": [
    "o = evaluate(rnn, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:31:00.275409Z",
     "start_time": "2020-08-20T13:31:00.252426Z"
    }
   },
   "outputs": [],
   "source": [
    "o.topk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:26:00.271309Z",
     "start_time": "2020-08-20T13:26:00.251315Z"
    }
   },
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:37:26.165119Z",
     "start_time": "2020-08-20T13:37:26.148164Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_category(title):\n",
    "    title = title_to_tensor(title)\n",
    "    output = evaluate(rnn, title)\n",
    "    topn, topi = output.topk(1)\n",
    "    return categories[topi.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_category(title):\n",
    "#     title = title_to_tensor(title)\n",
    "#     output = evaluate(rnn, title)\n",
    "#     topn, topi = output.topk(1)\n",
    "#     return categories[topi.item()]\n",
    "# while True:\n",
    "#     title = input()\n",
    "#     if not title:\n",
    "#         break\n",
    "#     print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:40:17.526545Z",
     "start_time": "2020-08-20T13:40:17.508593Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:32:53.017140Z",
     "start_time": "2020-08-20T13:32:53.004177Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"【校招】今日头条后端开发工程师\", get_category(rnn, \"【校招】今日头条后端开发工程师\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:33:08.592301Z",
     "start_time": "2020-08-20T13:33:08.580281Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"毕业找房子\", get_category(rnn, \"毕业找房子\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:28:25.755093Z",
     "start_time": "2020-08-20T13:28:25.739137Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"学校附近的公寓\", get_category(rnn, \"学校附近的公寓\"))\n",
    "print(\"学校附近的公寓\", get_category(rnn, \"学校附近的公寓\"))\n",
    "print(\"考博经验帖\", get_category(rnn, \"考博经验帖\"))\n",
    "print(\"2021年秋季出国交流\", get_category(rnn, \"2021年秋季出国交流\"))\n",
    "print(\"考研学校选择，纠结，求师哥师姐指导\", get_category(rnn, \"考研学校选择，纠结，求师哥师姐指导\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
